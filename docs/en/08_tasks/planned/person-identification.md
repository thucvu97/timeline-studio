# Person Identification - Person Recognition and Tracking

> ⚡ **This module is integrated with [AI Content Intelligence Suite](ai-content-intelligence-epic.md) as an optional component**
> 
> Person Identification extends the base face detection from Scene Analysis Engine with specialized tracking, profiling, and privacy features. It enriches all three engines with person-specific data.

## 📋 Overview

Person Identification is an advanced module for face detection, person identification, and tracking their appearance throughout the entire video. The module uses modern machine learning algorithms to create smart cataloging of persons in the project.

## 🎯 Goals and Objectives

### Primary Goals:
1. **Automation** - automatic detection of all persons
2. **Accuracy** - minimum identification errors
3. **Tracking** - person tracking between frames
4. **Privacy** - compliance with privacy requirements

### Key Features:
- Face detection and recognition
- Person profile creation
- Tracking throughout the project
- Grouping by persons
- Anonymization when needed

## 🏗️ Technical Architecture

### Frontend Structure:
```
src/features/person-identification/
├── components/
│   ├── person-browser/        # Person browser
│   │   ├── person-grid.tsx    # Person grid
│   │   ├── person-card.tsx    # Person card
│   │   └── person-details.tsx # Person details
│   ├── face-detection/        # Face detection
│   │   ├── face-overlay.tsx   # Video overlay
│   │   ├── face-marker.tsx    # Face marker
│   │   └── detection-box.tsx  # Detection box
│   ├── person-timeline/       # Person timeline
│   │   ├── appearance-track.tsx # Appearance track
│   │   └── person-clips.tsx   # Clips with person
│   ├── identity-manager/      # Identity management
│   │   ├── merge-persons.tsx  # Merge persons
│   │   ├── split-person.tsx   # Split persons
│   │   └── person-editor.tsx  # Person editor
│   └── privacy/              # Privacy
│       ├── blur-faces.tsx    # Face blurring
│       └── anonymize.tsx     # Anonymization
├── hooks/
│   ├── use-face-detection.ts  # Face detection
│   ├── use-person-tracking.ts # Person tracking
│   └── use-person-data.ts    # Person data
├── services/
│   ├── face-detector.ts      # Face detector
│   ├── face-recognizer.ts    # Recognition
│   ├── person-tracker.ts     # Person tracker
│   └── identity-service.ts   # Identity service
└── types/
    └── person.ts             # Data types
```

### Backend Structure (Rust):
```
src-tauri/src/person_identification/
├── mod.rs                    # Main module
├── face_detection/           # Face detection
│   ├── detector.rs          # Detector (MTCNN/RetinaFace)
│   ├── landmarks.rs         # Facial landmarks
│   └── alignment.rs         # Face alignment
├── face_recognition/        # Recognition
│   ├── embeddings.rs        # Face embeddings
│   ├── matcher.rs           # Face matching
│   └── clustering.rs        # Clustering
├── tracking/                # Tracking
│   ├── multi_tracker.rs     # Multi-object tracking
│   ├── kalman_filter.rs     # Position prediction
│   └── re_identification.rs # Re-ID after loss
├── database/                # Database
│   ├── person_db.rs         # Person DB
│   └── embeddings_index.rs  # Embeddings index
└── commands.rs              # Tauri commands
```

## 📐 Functional Requirements

### 1. Face Detection

#### Detection Algorithms:
- **MTCNN** - Multi-task Cascaded CNN
- **RetinaFace** - high accuracy
- **YOLO-Face** - speed
- **MediaPipe Face** - real-time

#### Detection Parameters:
```typescript
interface FaceDetectionConfig {
    // Model
    model: 'mtcnn' | 'retinaface' | 'yolo' | 'mediapipe';
    
    // Parameters
    minFaceSize: number;        // Minimum face size
    confidenceThreshold: number; // Confidence threshold
    maxFaces: number;           // Max number of faces
    
    // Performance
    batchSize: number;          // Batch size
    skipFrames: number;         // Frame skipping
    useGPU: boolean;           // GPU acceleration
}
```

#### Detection Result:
```typescript
interface DetectedFace {
    bbox: BoundingBox;          // Face coordinates
    confidence: number;         // Confidence
    landmarks?: FacialLandmarks; // 68 face points
    
    // Attributes
    age?: number;              // Approximate age
    gender?: Gender;           // Gender
    emotion?: Emotion;         // Emotion
    
    // Quality
    blur: number;              // Blurriness
    occlusion: number;         // Occlusion
    pose: HeadPose;           // Head pose
}
```

### 2. Person Recognition

#### Face Embeddings:
```typescript
interface FaceEmbedding {
    vector: Float32Array;       // 128D or 512D vector
    quality: number;           // Embedding quality
    
    // Metadata
    faceId: string;
    timestamp: Timecode;
    frameNumber: number;
}
```

#### Face Matching:
```typescript
class FaceMatcher {
    private threshold = 0.6;    // Similarity threshold
    
    match(embedding1: FaceEmbedding, embedding2: FaceEmbedding): MatchResult {
        const distance = this.cosineDistance(embedding1.vector, embedding2.vector);
        const similarity = 1 - distance;
        
        return {
            match: similarity > this.threshold,
            similarity,
            confidence: this.calculateConfidence(similarity, embedding1.quality, embedding2.quality)
        };
    }
}
```

### 3. Person Profile Creation

#### Profile Structure:
```typescript
interface PersonProfile {
    id: string;
    name?: string;              // Name (optional)
    
    // Biometrics
    faceEmbeddings: FaceEmbedding[]; // Multiple embeddings
    averageEmbedding: Float32Array;   // Average vector
    
    // Appearances
    appearances: Appearance[];
    totalScreenTime: Duration;
    firstAppearance: Timecode;
    lastAppearance: Timecode;
    
    // Statistics
    clipCount: number;          // Number of clips
    sceneCount: number;         // Number of scenes
    
    // Metadata
    tags: string[];
    notes?: string;
    thumbnails: Thumbnail[];
}

interface Appearance {
    clipId: string;
    startTime: Timecode;
    endTime: Timecode;
    confidence: number;
    
    // Tracking
    trackId: string;
    boundingBoxes: TimedBoundingBox[];
}
```

### 4. Person Tracking

#### Multi-Object Tracking:
```rust
pub struct PersonTracker {
    trackers: HashMap<PersonId, Box<dyn Tracker>>,
    kalman_filters: HashMap<PersonId, KalmanFilter>,
}

impl PersonTracker {
    pub fn update(&mut self, frame: &VideoFrame, detections: Vec<Detection>) {
        // Predict positions with Kalman filter
        for (id, kalman) in &mut self.kalman_filters {
            kalman.predict();
        }
        
        // Match detections with tracks
        let matches = self.hungarian_matching(&detections);
        
        // Update tracks
        for (track_id, detection_id) in matches {
            self.trackers[track_id].update(&detections[detection_id]);
            self.kalman_filters[track_id].update(&detections[detection_id]);
        }
        
        // Create new tracks
        for unmatched in unmatched_detections {
            self.create_new_track(unmatched);
        }
    }
}
```

#### Re-identification:
- Recovery after occlusion
- Tracking between scenes
- Robustness to lighting changes
- Work with different angles

### 5. Timeline Visualization

#### Person Timeline View:
```
Person Timeline:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
John Doe    ████  ████████    ████████
Jane Smith      ██████    ████    ████
Unknown #1  ██        ██████        ██
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
            0:00  1:00  2:00  3:00  4:00
```

#### Interactive Features:
- Click on person → show all clips
- Hover → face preview
- Drag & drop → reorder
- Right-click → context menu

### 6. Identity Management

#### Merge Persons:
```typescript
interface MergePersonsOperation {
    sourcePersons: PersonId[];
    targetPerson: PersonId;
    
    // Strategy
    mergeStrategy: {
        embeddings: 'all' | 'best' | 'average';
        name: 'keep' | 'prompt' | 'auto';
        appearances: 'merge' | 'recalculate';
    };
}
```

#### Split Person:
- Manual indication of different people
- Automatic by similarity threshold
- Visual grouping

### 7. Privacy and Anonymization

#### Privacy Features:
```typescript
interface PrivacyOptions {
    // Blurring
    blurFaces: {
        enabled: boolean;
        intensity: number;      // Blur strength
        tracking: boolean;      // Track movement
    };
    
    // Anonymization
    anonymize: {
        replaceWithAvatar: boolean;
        pixelate: boolean;
        blackBox: boolean;
    };
    
    // Exceptions
    whitelist: PersonId[];      // Don't blur
    blacklist: PersonId[];      // Always blur
}
```

#### GDPR Compliance:
- Right to deletion
- Person data export
- Processing consent
- Usage audit

### 8. Export and Integration

#### Export Formats:
```typescript
interface PersonDataExport {
    format: 'json' | 'csv' | 'xml' | 'vtt';
    
    // Data
    includeEmbeddings: boolean;
    includeThumbnails: boolean;
    includeTimecodes: boolean;
    
    // Filters
    persons?: PersonId[];
    timeRange?: TimeRange;
}
```

#### Subtitle Integration:
- Automatic speaker names
- Dialog synchronization
- Export to subtitle formats

## 🎨 UI/UX Design

### Person Browser:
```
┌─────────────────────────────────────────────────┐
│ Persons (12 detected)         [+Add] [Settings] │
├─────────────────────────────────────────────────┤
│ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐│
│ │   👤    │ │   👤    │ │   👤    │ │   👤    ││
│ │ John    │ │ Jane    │ │Unknown 1│ │Unknown 2││
│ │ 15 clips│ │ 8 clips │ │ 3 clips │ │ 2 clips ││
│ │ 5:30    │ │ 3:15    │ │ 1:20    │ │ 0:45    ││
│ └─────────┘ └─────────┘ └─────────┘ └─────────┘│
├─────────────────────────────────────────────────┤
│ Selected: John                                  │
│ First seen: 00:00:15 | Last: 00:45:30         │
│ Total screen time: 5:30 (23% of video)        │
│                                                │
│ [Show on Timeline] [Export] [Blur Face]        │
└─────────────────────────────────────────────────┘
```

### Face Detection Overlay:
```
Video Preview with Face Detection:
┌─────────────────────────────────────┐
│                                     │
│     ┌─────────┐                    │
│     │ John    │                    │
│     │ 95%     │      Jane          │
│     └─────────┘    ┌─────────┐    │
│                    │  87%    │    │
│                    └─────────┘    │
│                                     │
└─────────────────────────────────────┘
[✓] Show names [✓] Show confidence
```

## 🔧 Technical Details

### Face Recognition Pipeline:

```rust
use dlib::face_recognition;

pub struct FaceRecognitionPipeline {
    detector: Box<dyn FaceDetector>,
    aligner: FaceAligner,
    embedder: FaceEmbedder,
    matcher: FaceMatcher,
}

impl FaceRecognitionPipeline {
    pub async fn process_frame(&self, frame: &VideoFrame) -> Vec<PersonDetection> {
        // 1. Face detection
        let faces = self.detector.detect_faces(frame).await?;
        
        // 2. Alignment
        let aligned_faces = faces.iter()
            .map(|face| self.aligner.align(frame, face))
            .collect();
        
        // 3. Extract embeddings
        let embeddings = self.embedder.extract_embeddings(&aligned_faces).await?;
        
        // 4. Match with known persons
        let identities = embeddings.iter()
            .map(|emb| self.matcher.identify(emb))
            .collect();
        
        // 5. Form result
        faces.iter().zip(identities)
            .map(|(face, identity)| PersonDetection {
                bbox: face.bbox,
                person_id: identity,
                confidence: face.confidence,
            })
            .collect()
    }
}
```

### Efficient Embeddings Storage:

```rust
use hnsw::{Hnsw, Searcher};

pub struct EmbeddingsIndex {
    index: Hnsw<f32, DistCosine>,
    embeddings: Vec<(PersonId, FaceEmbedding)>,
}

impl EmbeddingsIndex {
    pub fn search(&self, query: &[f32], k: usize) -> Vec<SearchResult> {
        let mut searcher = Searcher::default();
        let neighbors = self.index.search(query, k, &mut searcher);
        
        neighbors.into_iter()
            .map(|item| SearchResult {
                person_id: self.embeddings[item.index].0.clone(),
                distance: item.distance,
                confidence: 1.0 - item.distance,
            })
            .collect()
    }
}
```

## 📊 Implementation Plan

### Phase 1: Basic Detection (2 weeks)
- [ ] Face detection models integration
- [ ] UI for face display
- [ ] Basic detection saving
- [ ] Preview with bounding boxes

### Phase 2: Recognition (3 weeks)
- [ ] Face embeddings extraction
- [ ] Face matching
- [ ] Person profile creation
- [ ] Person browser UI

### Phase 3: Tracking (2 weeks)
- [ ] Multi-object tracking
- [ ] Re-identification
- [ ] Timeline visualization
- [ ] Identity management

### Phase 4: Advanced Features (2 weeks)
- [ ] Privacy and anonymization
- [ ] Data export
- [ ] Subtitle integration
- [ ] Performance optimization

## 🎯 Success Metrics

### Accuracy:
- 95%+ face detection accuracy
- 90%+ recognition accuracy
- 85%+ tracking accuracy

### Performance:
- Real-time for HD video
- <1s per frame for 4K
- Batch processing 10x faster

### Usability:
- Automatic grouping
- Simple person management
- Fast person search

## 🔗 Integration

### With Other Modules:
- **Timeline** - person display
- **Scene Analyzer** - persons in scenes
- **Subtitles** - speaker names
- **Export** - person metadata

### Developer API:
```typescript
interface PersonIdentificationAPI {
    // Detection
    detectFaces(frame: VideoFrame): Promise<DetectedFace[]>;
    
    // Recognition
    recognizePerson(face: DetectedFace): Promise<PersonId>;
    createPerson(faces: DetectedFace[]): Promise<PersonProfile>;
    
    // Tracking
    trackPersons(video: VideoSegment): Promise<PersonTrack[]>;
    
    // Management
    mergePersons(persons: PersonId[]): Promise<PersonId>;
    splitPerson(person: PersonId, clusters: number): Promise<PersonId[]>;
    
    // Privacy
    blurFaces(video: VideoSegment, options: PrivacyOptions): Promise<void>;
}
```

## 📚 References

- [MTCNN Paper](https://arxiv.org/abs/1604.02878)
- [RetinaFace](https://arxiv.org/abs/1905.00641)
- [FaceNet](https://arxiv.org/abs/1503.03832)
- [Deep SORT](https://arxiv.org/abs/1703.07402)

---

*Document will be updated as the module develops*