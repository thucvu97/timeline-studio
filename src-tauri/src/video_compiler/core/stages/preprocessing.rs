//! Preprocessing Stage - –≠—Ç–∞–ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤

use async_trait::async_trait;
use std::path::PathBuf;
use std::time::Duration;

use super::{PipelineContext, PipelineStage};
use crate::video_compiler::error::{Result, VideoCompilerError};
use crate::video_compiler::schema::ClipSource;

/// –≠—Ç–∞–ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
pub struct PreprocessingStage;

impl PreprocessingStage {
  pub fn new() -> Self {
    Self
  }

  /// –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤
  async fn prepare_media_files(&self, context: &mut PipelineContext) -> Result<()> {
    log::info!("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤...");

    let mut processed_files = 0;
    let total_files = self.count_media_files(context);

    let tracks = context.project.tracks.clone();
    for (track_idx, track) in tracks.iter().enumerate() {
      for (clip_idx, clip) in track.clips.iter().enumerate() {
        if context.is_cancelled() {
          return Err(VideoCompilerError::CancelledError(
            "Preprocessing cancelled".to_string(),
          ));
        }

        match &clip.source {
          ClipSource::File(path) => {
            let processed_path = self
              .preprocess_media_file(
                path.as_str(),
                &format!("track_{}_clip_{}", track_idx, clip_idx),
                context,
              )
              .await?;

            // –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã
            context.add_intermediate_file(
              format!("preprocessed_track_{}_clip_{}", track_idx, clip_idx),
              processed_path,
            );
          }
          ClipSource::Generated { .. } => {
            // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ–¥–∏–∞—Ñ–∞–π–ª
            let generated_path = self
              .generate_media_file(
                clip,
                &format!("generated_track_{}_clip_{}", track_idx, clip_idx),
                context,
              )
              .await?;

            context.add_intermediate_file(
              format!("generated_track_{}_clip_{}", track_idx, clip_idx),
              generated_path,
            );
          }
          ClipSource::Stream(_) => {
            log::warn!("Stream sources are not yet supported in preprocessing");
          }
          ClipSource::Device(_) => {
            log::warn!("Device sources are not yet supported in preprocessing");
          }
        }

        processed_files += 1;
        let progress = (processed_files * 100 / total_files) as u64;
        context.update_progress(progress, "Preprocessing").await?;
      }
    }

    log::info!("‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {} –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤", processed_files);
    Ok(())
  }

  /// –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤
  fn count_media_files(&self, context: &PipelineContext) -> usize {
    context
      .project
      .tracks
      .iter()
      .map(|track| track.clips.len())
      .sum()
  }

  /// –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞
  async fn preprocess_media_file(
    &self,
    source_path: &str,
    identifier: &str,
    context: &PipelineContext,
  ) -> Result<PathBuf> {
    log::debug!("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {}", source_path);

    let source = PathBuf::from(source_path);
    let output_path = context.get_temp_file_path(&format!("{}_preprocessed.mp4", identifier));

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    if self.needs_preprocessing(&source, context).await? {
      // –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ FFmpeg
      self
        .run_ffmpeg_preprocessing(&source, &output_path, context)
        .await?;
      log::debug!("‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {:?}", output_path);
    } else {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
      tokio::fs::copy(&source, &output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      log::debug!("üìã –§–∞–π–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {:?}", output_path);
    }

    Ok(output_path)
  }

  /// –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
  async fn needs_preprocessing(
    &self,
    source_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<bool> {
    // –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ —á–µ—Ä–µ–∑ FFprobe
    let file_info = self.get_media_info(source_path).await?;
    let export_settings = &context.project.settings;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    if let (Some(width), Some(height)) = (file_info.width, file_info.height) {
      if width != export_settings.resolution.width || height != export_settings.resolution.height {
        log::debug!(
          "–¢—Ä–µ–±—É–µ—Ç—Å—è –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è: {}x{} -> {}x{}",
          width,
          height,
          export_settings.resolution.width,
          export_settings.resolution.height
        );
        return Ok(true);
      }
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥–µ–∫
    if let Some(codec) = &file_info.codec {
      if codec != &"libx264" {
        log::debug!("–¢—Ä–µ–±—É–µ—Ç—Å—è –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–¥–µ–∫–∞: {} -> {}", codec, "libx264");
        return Ok(true);
      }
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º FPS
    if let Some(fps) = file_info.fps {
      if (fps - export_settings.frame_rate).abs() > 0.1 {
        log::debug!(
          "–¢—Ä–µ–±—É–µ—Ç—Å—è –∏–∑–º–µ–Ω–µ–Ω–∏–µ FPS: {} -> {}",
          fps,
          export_settings.frame_rate
        );
        return Ok(true);
      }
    }

    Ok(false)
  }

  /// –ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ FFmpeg
  async fn run_ffmpeg_preprocessing(
    &self,
    input_path: &PathBuf,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vcodec")
      .arg(&"libx264")
      .arg("-s")
      .arg(format!(
        "{}x{}",
        export_settings.resolution.width, export_settings.resolution.height
      ))
      .arg("-r")
      .arg(export_settings.frame_rate.to_string())
      .arg("-b:v")
      .arg(format!("{}k", export_settings.export.video_bitrate / 1000))
      .arg("-preset")
      .arg(
        &export_settings
          .export
          .preset
          .as_ref()
          .unwrap_or(&"medium".to_string()),
      )
      .arg("-y") // –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Ñ–∞–π–ª
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::IoError(error_msg.to_string()));
    }

    Ok(())
  }

  /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞
  async fn generate_media_file(
    &self,
    clip: &crate::video_compiler::schema::Clip,
    identifier: &str,
    context: &PipelineContext,
  ) -> Result<PathBuf> {
    log::debug!("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–∞ –¥–ª—è –∫–ª–∏–ø–∞: {}", identifier);

    let output_path = context.get_temp_file_path(&format!("{}_generated.mp4", identifier));

    match &clip.source {
      ClipSource::Generated => {
        // Default to generating a color clip
        let default_color = Some("#000000".to_string());
        let default_duration = clip.get_timeline_duration();

        self
          .generate_color_clip(&default_color, default_duration, &output_path, context)
          .await?;
      }
      _ => {
        return Err(VideoCompilerError::ValidationError(
          "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏".to_string(),
        ));
      }
    }

    log::debug!("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {:?}", output_path);
    Ok(output_path)
  }

  /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –∫–ª–∏–ø–∞
  async fn generate_color_clip(
    &self,
    color: &Option<String>,
    duration: f64,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;
    let color_value = color.as_deref().unwrap_or("#000000");

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("lavfi")
      .arg("-i")
      .arg(format!(
        "color={}:size={}x{}:duration={}:rate={}",
        color_value,
        export_settings.resolution.width,
        export_settings.resolution.height,
        duration,
        export_settings.frame_rate
      ))
      .arg("-c:v")
      .arg(&"libx264")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::IoError(error_msg.to_string()));
    }

    Ok(())
  }

  /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —à—É–º–æ–≤–æ–≥–æ –∫–ª–∏–ø–∞
  async fn generate_noise_clip(
    &self,
    duration: f64,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("lavfi")
      .arg("-i")
      .arg(format!(
        "noise=size={}x{}:duration={}:rate={}",
        export_settings.resolution.width,
        export_settings.resolution.height,
        duration,
        export_settings.frame_rate
      ))
      .arg("-c:v")
      .arg(&"libx264")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::IoError(error_msg.to_string()));
    }

    Ok(())
  }

  /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –∫–ª–∏–ø–∞
  async fn generate_gradient_clip(
    &self,
    color: &Option<String>,
    duration: f64,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;
    let start_color = color.as_deref().unwrap_or("#000000");

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("lavfi")
      .arg("-i")
      .arg(format!(
        "gradients=size={}x{}:duration={}:rate={}:c0={}:c1=#ffffff",
        export_settings.resolution.width,
        export_settings.resolution.height,
        duration,
        export_settings.frame_rate,
        start_color
      ))
      .arg("-c:v")
      .arg(&"libx264")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::IoError(error_msg.to_string()));
    }

    Ok(())
  }

  /// –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ–¥–∏–∞—Ñ–∞–π–ª–µ
  async fn get_media_info(&self, file_path: &PathBuf) -> Result<MediaInfo> {
    let mut command = tokio::process::Command::new("ffprobe");
    command
      .arg("-v")
      .arg("quiet")
      .arg("-print_format")
      .arg("json")
      .arg("-show_format")
      .arg("-show_streams")
      .arg(file_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::IoError(error_msg.to_string()));
    }

    let json_output = String::from_utf8_lossy(&output.stdout);
    let info: serde_json::Value = serde_json::from_str(&json_output)
      .map_err(|e| VideoCompilerError::SerializationError(e.to_string()))?;

    // –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–µ
    let mut media_info = MediaInfo::default();

    if let Some(streams) = info["streams"].as_array() {
      for stream in streams {
        if stream["codec_type"] == "video" {
          media_info.width = stream["width"].as_u64().map(|w| w as u32);
          media_info.height = stream["height"].as_u64().map(|h| h as u32);
          media_info.codec = stream["codec_name"].as_str().map(|s| s.to_string());

          // –ü–∞—Ä—Å–∏–º FPS
          if let Some(fps_str) = stream["r_frame_rate"].as_str() {
            if let Some(fps) = self.parse_fps(fps_str) {
              media_info.fps = Some(fps);
            }
          }
          break;
        }
      }
    }

    Ok(media_info)
  }

  /// –ü–∞—Ä—Å–∏–Ω–≥ FPS –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "30/1"
  fn parse_fps(&self, fps_str: &str) -> Option<f64> {
    if let Some((num_str, den_str)) = fps_str.split_once('/') {
      if let (Ok(num), Ok(den)) = (num_str.parse::<f64>(), den_str.parse::<f64>()) {
        if den > 0.0 {
          return Some(num / den);
        }
      }
    }
    fps_str.parse().ok()
  }
}

#[async_trait]
impl PipelineStage for PreprocessingStage {
  async fn process(&self, context: &mut PipelineContext) -> Result<()> {
    log::info!("üîÑ === –≠—Ç–∞–ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ ===");

    // –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    context.update_progress(0, "Preprocessing").await?;

    // –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ–¥–∏–∞—Ñ–∞–π–ª—ã
    self.prepare_media_files(context).await?;

    log::info!("‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ");
    Ok(())
  }

  fn name(&self) -> &str {
    "Preprocessing"
  }

  fn estimated_duration(&self) -> Duration {
    Duration::from_secs(60) // –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
  }
}

impl Default for PreprocessingStage {
  fn default() -> Self {
    Self::new()
  }
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ–¥–∏–∞—Ñ–∞–π–ª–µ
#[derive(Debug, Default)]
struct MediaInfo {
  width: Option<u32>,
  height: Option<u32>,
  fps: Option<f64>,
  codec: Option<String>,
}

#[cfg(test)]
mod tests {
  use super::*;

  #[test]
  fn test_fps_parsing() {
    let stage = PreprocessingStage::new();
    assert_eq!(stage.parse_fps("30/1"), Some(30.0));
    assert_eq!(stage.parse_fps("24000/1001"), Some(23.976023976023978));
    assert_eq!(stage.parse_fps("25"), Some(25.0));
    assert_eq!(stage.parse_fps("invalid"), None);
  }

  #[tokio::test]
  async fn test_preprocessing_stage_basic() {
    let stage = PreprocessingStage::new();
    assert_eq!(stage.name(), "Preprocessing");
    assert!(!stage.estimated_duration().is_zero());
  }
}
