//! Composition Stage - –≠—Ç–∞–ø –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –≤–∏–¥–µ–æ

use async_trait::async_trait;
use std::path::{Path, PathBuf};
use std::time::Duration;

use super::{PipelineContext, PipelineStage};
use crate::video_compiler::error::{Result, VideoCompilerError};
use crate::video_compiler::schema::{Clip, Effect, Filter, Track};

/// –≠—Ç–∞–ø –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
pub struct CompositionStage;

impl CompositionStage {
  pub fn new() -> Self {
    Self
  }

  /// –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–π —Å—Ü–µ–Ω—ã
  async fn create_composition(&self, context: &mut PipelineContext) -> Result<()> {
    log::info!("üé¨ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–π —Å—Ü–µ–Ω—ã...");

    let composition_path = context.get_temp_file_path("composition.mp4");

    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç—Ä–µ–∫–∏ –ø–æ —Å–ª–æ—è–º
    let mut layer_outputs = Vec::new();
    let tracks_len = context.project.tracks.len();

    for (track_idx, track) in context.project.tracks.clone().iter().enumerate() {
      if context.is_cancelled() {
        return Err(VideoCompilerError::CancelledError(
          "–ö–æ–º–ø–æ–∑–∏—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞".to_string(),
        ));
      }

      let track_output = self.process_track(track, track_idx, context).await?;
      layer_outputs.push(track_output);

      let progress = ((track_idx + 1) * 70 / tracks_len) as u64;
      context.update_progress(progress, "Composition").await?;
    }

    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–ª–æ–∏
    self
      .combine_layers(&layer_outputs, &composition_path, context)
      .await?;
    context.update_progress(90, "Composition").await?;

    // –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã
    context.add_intermediate_file("composition".to_string(), composition_path);

    log::info!("‚úÖ –ö–æ–º–ø–æ–∑–∏—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞");
    Ok(())
  }

  /// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞
  async fn process_track(
    &self,
    track: &Track,
    track_idx: usize,
    context: &mut PipelineContext,
  ) -> Result<PathBuf> {
    log::debug!("üéµ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ–∫–∞ {track_idx}");

    let track_output = context.get_temp_file_path(&format!("track_{track_idx}.mp4"));

    if track.clips.is_empty() {
      // –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ç—Ä–µ–∫
      self.create_empty_track(&track_output, context).await?;
      return Ok(track_output);
    }

    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–ª–∏–ø—ã –≤ —Ç—Ä–µ–∫–µ
    let mut clip_outputs = Vec::new();
    for (clip_idx, clip) in track.clips.iter().enumerate() {
      let clip_output = self
        .process_clip(clip, track_idx, clip_idx, context)
        .await?;
      clip_outputs.push(clip_output);
    }

    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–ª–∏–ø—ã –≤ –æ–¥–∏–Ω —Ç—Ä–µ–∫
    self
      .concatenate_clips(&clip_outputs, &track_output, context)
      .await?;

    log::debug!("‚úÖ –¢—Ä–µ–∫ {track_idx} –æ–±—Ä–∞–±–æ—Ç–∞–Ω");
    Ok(track_output)
  }

  /// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–ª–∏–ø–∞
  async fn process_clip(
    &self,
    clip: &Clip,
    track_idx: usize,
    clip_idx: usize,
    context: &mut PipelineContext,
  ) -> Result<PathBuf> {
    log::debug!("üéûÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∏–ø–∞ {track_idx}:{clip_idx}");

    // –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
    let source_key = if matches!(
      clip.source,
      crate::video_compiler::schema::ClipSource::Generated
    ) {
      format!("generated_track_{track_idx}_clip_{clip_idx}")
    } else {
      format!("preprocessed_track_{track_idx}_clip_{clip_idx}")
    };

    let source_path = context.get_intermediate_file(&source_key).ok_or_else(|| {
      VideoCompilerError::InternalError(format!(
        "–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –∫–ª–∏–ø–∞ {track_idx}:{clip_idx} –Ω–µ –Ω–∞–π–¥–µ–Ω"
      ))
    })?;

    let clip_output = context.get_temp_file_path(&format!("clip_{track_idx}_{clip_idx}.mp4"));

    // –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–µ–∑–∫—É –≤—Ä–µ–º–µ–Ω–∏
    let trimmed_path = self
      .apply_time_trim(
        source_path,
        clip.start_time,
        clip.end_time,
        &context.get_temp_file_path(&format!("trimmed_{track_idx}_{clip_idx}.mp4")),
        context,
      )
      .await?;

    // –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã
    let effects_applied_path = if !clip.effects.is_empty() {
      // –ò—â–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –ø–æ ID
      let actual_effects: Vec<&Effect> = clip
        .effects
        .iter()
        .filter_map(|effect_id| context.project.effects.iter().find(|e| &e.id == effect_id))
        .collect();

      if !actual_effects.is_empty() {
        self
          .apply_effects(
            &trimmed_path,
            &actual_effects,
            &context.get_temp_file_path(&format!("effects_{track_idx}_{clip_idx}.mp4")),
            context,
          )
          .await?
      } else {
        trimmed_path
      }
    } else {
      trimmed_path
    };

    // –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    let filters_applied_path = if !clip.filters.is_empty() {
      // –ò—â–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ ID
      let actual_filters: Vec<&Filter> = clip
        .filters
        .iter()
        .filter_map(|filter_id| context.project.filters.iter().find(|f| &f.id == filter_id))
        .collect();

      if !actual_filters.is_empty() {
        self
          .apply_filters(
            &effects_applied_path,
            &actual_filters,
            &context.get_temp_file_path(&format!("filters_{track_idx}_{clip_idx}.mp4")),
            context,
          )
          .await?
      } else {
        effects_applied_path
      }
    } else {
      effects_applied_path
    };

    // –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
    self
      .apply_positioning(&filters_applied_path, clip, &clip_output, context)
      .await?;

    log::debug!("‚úÖ –ö–ª–∏–ø {track_idx}:{clip_idx} –æ–±—Ä–∞–±–æ—Ç–∞–Ω");
    Ok(clip_output)
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
  async fn apply_time_trim(
    &self,
    input_path: &PathBuf,
    start_time: f64,
    end_time: f64,
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<PathBuf> {
    let duration = end_time - start_time;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-ss")
      .arg(start_time.to_string())
      .arg("-t")
      .arg(duration.to_string())
      .arg("-c")
      .arg("copy")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(output_path.clone())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
  async fn apply_effects(
    &self,
    input_path: &Path,
    effects: &[&Effect],
    output_path: &Path,
    _context: &PipelineContext,
  ) -> Result<PathBuf> {
    let mut current_input = input_path.to_path_buf();

    for (temp_counter, effect) in effects.iter().enumerate() {
      let temp_output = if temp_counter == effects.len() - 1 {
        output_path.to_path_buf()
      } else {
        PathBuf::from(format!(
          "{}_temp_{}.mp4",
          output_path.file_stem().unwrap().to_string_lossy(),
          temp_counter
        ))
      };

      self
        .apply_single_effect(&current_input, effect, &temp_output)
        .await?;
      current_input = temp_output;
    }

    Ok(output_path.to_path_buf())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
  async fn apply_single_effect(
    &self,
    input_path: &PathBuf,
    effect: &Effect,
    output_path: &PathBuf,
  ) -> Result<()> {
    let filter_string = match effect.effect_type {
      crate::video_compiler::schema::effects::EffectType::AudioFadeIn => {
        let duration = effect
          .parameters
          .get("duration")
          .and_then(|d| match d {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(1.0);
        format!("fade=in:0:{duration}")
      }
      crate::video_compiler::schema::effects::EffectType::AudioFadeOut => {
        let duration = effect
          .parameters
          .get("duration")
          .and_then(|d| match d {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(1.0);
        format!("fade=out:st={duration}:d={duration}")
      }
      crate::video_compiler::schema::effects::EffectType::Blur => {
        let radius = effect
          .parameters
          .get("radius")
          .and_then(|r| match r {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(5.0);
        format!("boxblur={radius}")
      }
      crate::video_compiler::schema::effects::EffectType::Brightness => {
        let value = effect
          .parameters
          .get("value")
          .and_then(|v| match v {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(0.0);
        format!("eq=brightness={value}")
      }
      crate::video_compiler::schema::effects::EffectType::Contrast => {
        let value = effect
          .parameters
          .get("value")
          .and_then(|v| match v {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(1.0);
        format!("eq=contrast={value}")
      }
      _ => {
        log::warn!("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç: {:?}", effect.effect_type);
        return Ok(());
      }
    };

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vf")
      .arg(filter_string)
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
  async fn apply_filters(
    &self,
    input_path: &PathBuf,
    filters: &[&Filter],
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<PathBuf> {
    let mut filter_chains = Vec::new();

    for filter in filters {
      let filter_string = match filter.filter_type {
        crate::video_compiler::schema::effects::FilterType::Brightness => {
          let value = filter.parameters.get("value").unwrap_or(&0.0);
          format!("eq=brightness={value}")
        }
        crate::video_compiler::schema::effects::FilterType::Contrast => {
          let value = filter.parameters.get("value").unwrap_or(&1.0);
          format!("eq=contrast={value}")
        }
        crate::video_compiler::schema::effects::FilterType::Saturation => {
          let value = filter.parameters.get("value").unwrap_or(&1.0);
          format!("eq=saturation={value}")
        }
        crate::video_compiler::schema::effects::FilterType::Blur => {
          let radius = filter.parameters.get("radius").unwrap_or(&5.0);
          format!("boxblur={radius}")
        }
        crate::video_compiler::schema::effects::FilterType::Sharpen => {
          "unsharp=5:5:1.0:5:5:0.0".to_string()
        }
        _ => {
          log::warn!("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–∏–ª—å—Ç—Ä: {:?}", filter.filter_type);
          continue;
        }
      };
      filter_chains.push(filter_string);
    }

    if filter_chains.is_empty() {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
      tokio::fs::copy(input_path, output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      return Ok(output_path.clone());
    }

    let combined_filter = filter_chains.join(",");

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vf")
      .arg(combined_filter)
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(output_path.clone())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
  async fn apply_positioning(
    &self,
    input_path: &PathBuf,
    clip: &Clip,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;

    // –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –∏ —Ä–∞–∑–º–µ—Ä –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    let default_transform = Default::default();
    let transform = clip.transform.as_ref().unwrap_or(&default_transform);
    let width = export_settings.resolution.width;
    let height = export_settings.resolution.height;
    let x = (transform.position_x * width as f32) as i32;
    let y = (transform.position_y * height as f32) as i32;
    let scaled_width = (transform.scale_x * width as f32) as i32;
    let scaled_height = (transform.scale_y * height as f32) as i32;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vf")
      .arg(format!(
        "scale={scaled_width}:{scaled_height},pad={width}:{height}:{x}:{y}:black"
      ))
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–ª–∏–ø–æ–≤ –≤ —Ç—Ä–µ–∫–µ
  async fn concatenate_clips(
    &self,
    clip_paths: &[PathBuf],
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<()> {
    if clip_paths.is_empty() {
      return Err(VideoCompilerError::InternalError(
        "–ù–µ—Ç –∫–ª–∏–ø–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è".to_string(),
      ));
    }

    if clip_paths.len() == 1 {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–ª–∏–ø
      tokio::fs::copy(&clip_paths[0], output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      return Ok(());
    }

    // –°–æ–∑–¥–∞–µ–º concat —Ñ–∞–π–ª
    let concat_file = output_path.parent().unwrap().join("concat_list.txt");
    let mut concat_content = String::new();

    for path in clip_paths {
      concat_content.push_str(&format!("file '{}'\n", path.display()));
    }

    tokio::fs::write(&concat_file, concat_content)
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("concat")
      .arg("-safe")
      .arg("0")
      .arg("-i")
      .arg(&concat_file)
      .arg("-c")
      .arg("copy")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π concat —Ñ–∞–π–ª
    let _ = tokio::fs::remove_file(&concat_file).await;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–ª–æ–µ–≤ (—Ç—Ä–µ–∫–æ–≤)
  async fn combine_layers(
    &self,
    layer_paths: &[PathBuf],
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<()> {
    if layer_paths.is_empty() {
      return Err(VideoCompilerError::InternalError(
        "–ù–µ—Ç —Å–ª–æ–µ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è".to_string(),
      ));
    }

    if layer_paths.len() == 1 {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ª–æ–π
      tokio::fs::copy(&layer_paths[0], output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      return Ok(());
    }

    // –°–æ–∑–¥–∞–µ–º —Å–ª–æ–∂–Ω—É—é —Ñ–∏–ª—å—Ç—Ä-—Å—Ö–µ–º—É –¥–ª—è overlay
    let mut command = tokio::process::Command::new("ffmpeg");

    // –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
    for path in layer_paths {
      command.arg("-i").arg(path);
    }

    // –°–æ–∑–¥–∞–µ–º filter_complex –¥–ª—è overlay
    let mut filter_complex = String::new();
    let mut current_label = "[0:v]".to_string();

    for i in 1..layer_paths.len() {
      let next_label = if i == layer_paths.len() - 1 {
        "[out]".to_string()
      } else {
        format!("[tmp{i}]")
      };

      filter_complex.push_str(&format!("{current_label}[{i}:v]overlay=0:0{next_label}; "));

      current_label = next_label.clone();
    }

    // –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π "; "
    filter_complex = filter_complex.trim_end_matches("; ").to_string();

    command
      .arg("-filter_complex")
      .arg(filter_complex)
      .arg("-map")
      .arg("[out]")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ç—Ä–µ–∫–∞
  async fn create_empty_track(
    &self,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("lavfi")
      .arg("-i")
      .arg(format!(
        "color=black:size={}x{}:duration=1:rate={}",
        export_settings.resolution.width,
        export_settings.resolution.height,
        export_settings.frame_rate
      ))
      .arg("-c:v")
      .arg("libx264")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }
}

#[async_trait]
impl PipelineStage for CompositionStage {
  async fn process(&self, context: &mut PipelineContext) -> Result<()> {
    log::info!("üé¨ === –≠—Ç–∞–ø –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ ===");

    // –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    context.update_progress(0, "Composition").await?;

    // –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–∑–∏—Ü–∏—é
    self.create_composition(context).await?;

    log::info!("‚úÖ –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ");
    Ok(())
  }

  fn name(&self) -> &str {
    "Composition"
  }

  fn estimated_duration(&self) -> Duration {
    Duration::from_secs(120) // –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
  }
}

impl Default for CompositionStage {
  fn default() -> Self {
    Self::new()
  }
}

#[cfg(test)]
mod tests {
  use super::*;
  use crate::video_compiler::schema::{
    effects::{Effect, EffectParameter, EffectType, Filter, FilterType},
    timeline::{Clip, Track as SchemaTrack, TrackType, TransformSettings},
  };
  use std::collections::HashMap;
  use std::path::Path;
  use tempfile::TempDir;
  use tokio;

  fn create_test_context(temp_dir: &TempDir) -> PipelineContext {
    // Use the actual Project schema from the codebase
    let project =
      crate::video_compiler::schema::project::ProjectSchema::new("Test Project".to_string());
    let output_path = temp_dir.path().join("output.mp4");

    let mut context = PipelineContext::new(project, output_path);
    // Override temp_dir to use our test directory
    context.temp_dir = temp_dir.path().to_path_buf();
    context
  }

  fn create_mock_video_file(path: &Path) -> Result<()> {
    // Create a minimal mock video file
    std::fs::write(path, b"mock video content")?;
    Ok(())
  }

  #[test]
  fn test_composition_stage_creation() {
    let stage = CompositionStage::new();
    assert_eq!(stage.name(), "Composition");
    assert_eq!(stage.estimated_duration(), Duration::from_secs(120));
  }

  #[test]
  fn test_composition_stage_default() {
    let stage = CompositionStage;
    assert_eq!(stage.name(), "Composition");
  }

  #[tokio::test]
  async fn test_create_empty_track() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let output_path = temp_dir.path().join("empty_track.mp4");

    // –¢–µ—Å—Ç –±—É–¥–µ—Ç —É—Å–ø–µ—à–Ω—ã–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ FFmpeg —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    // –í —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ —ç—Ç–æ —Å–æ–∑–¥–∞—Å—Ç –ø—É—Å—Ç–æ–π —á–µ—Ä–Ω—ã–π –≤–∏–¥–µ–æ—Ñ–∞–π–ª
    let result = stage.create_empty_track(&output_path, &context).await;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –±–µ–∑ –ø–∞–Ω–∏–∫–∏
    // –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—à–∏–±–∫–æ–π –µ—Å–ª–∏ FFmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —á—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    match result {
      Ok(()) => {
        // –ï—Å–ª–∏ FFmpeg —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω
        assert!(output_path.exists());
      }
      Err(VideoCompilerError::FFmpegError { .. }) => {
        // –û–∂–∏–¥–∞–µ–º–∞—è –æ—à–∏–±–∫–∞ –µ—Å–ª–∏ FFmpeg –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥–µ
      }
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_time_trim() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("trimmed.mp4");

    create_mock_video_file(&input_path).unwrap();

    let result = stage
      .apply_time_trim(&input_path, 0.0, 5.0, &output_path, &context)
      .await;

    // –¢–µ—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤—ã–∑–æ–≤–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω–∞–ª–∏—á–∏—è FFmpeg
    match result {
      Ok(path) => {
        assert_eq!(path, output_path);
      }
      Err(VideoCompilerError::FFmpegError { .. }) => {
        // –û–∂–∏–¥–∞–µ–º–æ –µ—Å–ª–∏ FFmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
      }
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_single_effect_blur() {
    let temp_dir = TempDir::new().unwrap();
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("blurred.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut parameters = HashMap::new();
    parameters.insert("radius".to_string(), EffectParameter::Float(10.0));

    let mut effect = Effect::new(EffectType::Blur, "Blur Effect".to_string());
    effect.parameters = parameters;

    let result = stage
      .apply_single_effect(&input_path, &effect, &output_path)
      .await;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ
    match result {
      Ok(()) => {}
      Err(VideoCompilerError::FFmpegError { .. }) => {
        // –û–∂–∏–¥–∞–µ–º–æ –µ—Å–ª–∏ FFmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
      }
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_single_effect_brightness() {
    let temp_dir = TempDir::new().unwrap();
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("bright.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut parameters = HashMap::new();
    parameters.insert("value".to_string(), EffectParameter::Float(0.2));

    let mut effect = Effect::new(EffectType::Brightness, "Brightness Effect".to_string());
    effect.parameters = parameters;

    let result = stage
      .apply_single_effect(&input_path, &effect, &output_path)
      .await;

    match result {
      Ok(()) => {}
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_single_effect_contrast() {
    let temp_dir = TempDir::new().unwrap();
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("contrast.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut parameters = HashMap::new();
    parameters.insert("value".to_string(), EffectParameter::Float(1.5));

    let mut effect = Effect::new(EffectType::Contrast, "Contrast Effect".to_string());
    effect.parameters = parameters;

    let result = stage
      .apply_single_effect(&input_path, &effect, &output_path)
      .await;

    match result {
      Ok(()) => {}
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_single_effect_audio_fade_in() {
    let temp_dir = TempDir::new().unwrap();
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("fade_in.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut parameters = HashMap::new();
    parameters.insert("duration".to_string(), EffectParameter::Float(2.0));

    let mut effect = Effect::new(EffectType::AudioFadeIn, "Audio Fade In".to_string());
    effect.parameters = parameters;

    let result = stage
      .apply_single_effect(&input_path, &effect, &output_path)
      .await;

    match result {
      Ok(()) => {}
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_single_effect_audio_fade_out() {
    let temp_dir = TempDir::new().unwrap();
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("fade_out.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut parameters = HashMap::new();
    parameters.insert("duration".to_string(), EffectParameter::Float(3.0));

    let mut effect = Effect::new(EffectType::AudioFadeOut, "Audio Fade Out".to_string());
    effect.parameters = parameters;

    let result = stage
      .apply_single_effect(&input_path, &effect, &output_path)
      .await;

    match result {
      Ok(()) => {}
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_single_effect_unsupported() {
    let temp_dir = TempDir::new().unwrap();
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("output.mp4");

    create_mock_video_file(&input_path).unwrap();

    // –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç
    let effect = Effect::new(EffectType::AudioEqualizer, "Unsupported Effect".to_string()); // –ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤ apply_single_effect

    let result = stage
      .apply_single_effect(&input_path, &effect, &output_path)
      .await;

    // –î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å Ok(()) –¥–ª—è –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
    assert!(result.is_ok());
  }

  #[tokio::test]
  async fn test_apply_effects_empty() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("effects.mp4");

    create_mock_video_file(&input_path).unwrap();

    let effects: Vec<&Effect> = vec![];

    let result = stage
      .apply_effects(&input_path, &effects, &output_path, &context)
      .await;

    assert!(result.is_ok());
    assert_eq!(result.unwrap(), output_path);
  }

  #[tokio::test]
  async fn test_apply_filters_brightness() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("filtered.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut parameters = HashMap::new();
    parameters.insert("value".to_string(), 0.3);

    let filter = Filter::new(FilterType::Brightness, "Brightness Filter".to_string());

    let filters = vec![&filter];

    let result = stage
      .apply_filters(&input_path, &filters, &output_path, &context)
      .await;

    match result {
      Ok(path) => assert_eq!(path, output_path),
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_filters_multiple() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("filtered.mp4");

    create_mock_video_file(&input_path).unwrap();

    let mut brightness_params = HashMap::new();
    brightness_params.insert("value".to_string(), 0.2);

    let mut contrast_params = HashMap::new();
    contrast_params.insert("value".to_string(), 1.3);

    let brightness_filter = Filter::new(FilterType::Brightness, "Brightness Filter".to_string());
    let contrast_filter = Filter::new(FilterType::Contrast, "Contrast Filter".to_string());

    let filters = vec![&brightness_filter, &contrast_filter];

    let result = stage
      .apply_filters(&input_path, &filters, &output_path, &context)
      .await;

    match result {
      Ok(path) => assert_eq!(path, output_path),
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_apply_filters_empty() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("output.mp4");

    create_mock_video_file(&input_path).unwrap();

    let filters: Vec<&Filter> = vec![];

    let result = stage
      .apply_filters(&input_path, &filters, &output_path, &context)
      .await;

    // –î–æ–ª–∂–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    assert!(result.is_ok());
    assert_eq!(result.unwrap(), output_path);
    assert!(output_path.exists());
  }

  #[tokio::test]
  async fn test_apply_positioning() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let input_path = temp_dir.path().join("input.mp4");
    let output_path = temp_dir.path().join("positioned.mp4");

    create_mock_video_file(&input_path).unwrap();

    let transform = TransformSettings {
      position_x: 0.1,
      position_y: 0.2,
      scale_x: 0.8,
      scale_y: 0.8,
      rotation: 0.0,
      anchor_x: 0.5,
      anchor_y: 0.5,
    };

    let mut clip = Clip::new(
      std::path::PathBuf::from(input_path.to_string_lossy().to_string()),
      0.0,
      5.0,
    );
    clip.transform = Some(transform);

    let result = stage
      .apply_positioning(&input_path, &clip, &output_path, &context)
      .await;

    match result {
      Ok(()) => {}
      Err(VideoCompilerError::FFmpegError { .. }) => {}
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_concatenate_clips_empty() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let output_path = temp_dir.path().join("concat.mp4");
    let clip_paths: Vec<PathBuf> = vec![];

    let result = stage
      .concatenate_clips(&clip_paths, &output_path, &context)
      .await;

    assert!(result.is_err());
    match result.unwrap_err() {
      VideoCompilerError::InternalError(msg) => {
        assert!(msg.contains("–ù–µ—Ç –∫–ª–∏–ø–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è"));
      }
      e => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_concatenate_clips_single() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let clip_path = temp_dir.path().join("clip1.mp4");
    let output_path = temp_dir.path().join("concat.mp4");

    create_mock_video_file(&clip_path).unwrap();

    let clip_paths = vec![clip_path.clone()];

    let result = stage
      .concatenate_clips(&clip_paths, &output_path, &context)
      .await;

    assert!(result.is_ok());
    assert!(output_path.exists());
  }

  #[tokio::test]
  async fn test_combine_layers_empty() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let output_path = temp_dir.path().join("combined.mp4");
    let layer_paths: Vec<PathBuf> = vec![];

    let result = stage
      .combine_layers(&layer_paths, &output_path, &context)
      .await;

    assert!(result.is_err());
    match result.unwrap_err() {
      VideoCompilerError::InternalError(msg) => {
        assert!(msg.contains("–ù–µ—Ç —Å–ª–æ–µ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è"));
      }
      e => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }

  #[tokio::test]
  async fn test_combine_layers_single() {
    let temp_dir = TempDir::new().unwrap();
    let context = create_test_context(&temp_dir);
    let stage = CompositionStage::new();

    let layer_path = temp_dir.path().join("layer1.mp4");
    let output_path = temp_dir.path().join("combined.mp4");

    create_mock_video_file(&layer_path).unwrap();

    let layer_paths = vec![layer_path.clone()];

    let result = stage
      .combine_layers(&layer_paths, &output_path, &context)
      .await;

    assert!(result.is_ok());
    assert!(output_path.exists());
  }

  #[test]
  fn test_effect_parameter_extraction() {
    let _stage = CompositionStage::new();

    // –¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ EffectParameter
    let mut _params = HashMap::new();
    _params.insert("float_val".to_string(), EffectParameter::Float(2.5));
    _params.insert("int_val".to_string(), EffectParameter::Int(10));
    _params.insert(
      "string_val".to_string(),
      EffectParameter::String("test".to_string()),
    );

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    // –≠—Ç–æ –∫–æ—Å–≤–µ–Ω–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Ç–µ—Å—Ç—ã —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –≤—ã—à–µ
  }

  #[tokio::test]
  async fn test_process_integration() {
    let temp_dir = TempDir::new().unwrap();
    let mut context = create_test_context(&temp_dir);

    // –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç—Ä–µ–∫ –±–µ–∑ –∫–ª–∏–ø–æ–≤
    let track = SchemaTrack::new(TrackType::Video, "Test Track".to_string());

    context.project.tracks = vec![track];

    let stage = CompositionStage::new();

    let result = stage.process(&mut context).await;

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –ø–∞–Ω–∏–∫–∏
    // –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—à–∏–±–∫–æ–π –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è FFmpeg, —á—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    match result {
      Ok(()) => {
        // –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª –¥–æ–±–∞–≤–ª–µ–Ω
        assert!(context.intermediate_files.contains_key("composition"));
      }
      Err(VideoCompilerError::FFmpegError { .. }) => {
        // –û–∂–∏–¥–∞–µ–º–æ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥–µ –±–µ–∑ FFmpeg
      }
      Err(e) => panic!("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {:?}", e),
    }
  }
}
