//! Composition Stage - –≠—Ç–∞–ø –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –≤–∏–¥–µ–æ

use async_trait::async_trait;
use std::path::{Path, PathBuf};
use std::time::Duration;

use super::{PipelineContext, PipelineStage};
use crate::video_compiler::error::{Result, VideoCompilerError};
use crate::video_compiler::schema::{Clip, Effect, Filter, Track};

/// –≠—Ç–∞–ø –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
pub struct CompositionStage;

impl CompositionStage {
  pub fn new() -> Self {
    Self
  }

  /// –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–π —Å—Ü–µ–Ω—ã
  async fn create_composition(&self, context: &mut PipelineContext) -> Result<()> {
    log::info!("üé¨ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–π —Å—Ü–µ–Ω—ã...");

    let composition_path = context.get_temp_file_path("composition.mp4");

    // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç—Ä–µ–∫–∏ –ø–æ —Å–ª–æ—è–º
    let mut layer_outputs = Vec::new();
    let tracks_len = context.project.tracks.len();

    for (track_idx, track) in context.project.tracks.clone().iter().enumerate() {
      if context.is_cancelled() {
        return Err(VideoCompilerError::CancelledError(
          "–ö–æ–º–ø–æ–∑–∏—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞".to_string(),
        ));
      }

      let track_output = self.process_track(track, track_idx, context).await?;
      layer_outputs.push(track_output);

      let progress = ((track_idx + 1) * 70 / tracks_len) as u64;
      context.update_progress(progress, "Composition").await?;
    }

    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–ª–æ–∏
    self
      .combine_layers(&layer_outputs, &composition_path, context)
      .await?;
    context.update_progress(90, "Composition").await?;

    // –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ñ–∞–π–ª—ã
    context.add_intermediate_file("composition".to_string(), composition_path);

    log::info!("‚úÖ –ö–æ–º–ø–æ–∑–∏—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞");
    Ok(())
  }

  /// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞
  async fn process_track(
    &self,
    track: &Track,
    track_idx: usize,
    context: &mut PipelineContext,
  ) -> Result<PathBuf> {
    log::debug!("üéµ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ–∫–∞ {track_idx}");

    let track_output = context.get_temp_file_path(&format!("track_{track_idx}.mp4"));

    if track.clips.is_empty() {
      // –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ç—Ä–µ–∫
      self.create_empty_track(&track_output, context).await?;
      return Ok(track_output);
    }

    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–ª–∏–ø—ã –≤ —Ç—Ä–µ–∫–µ
    let mut clip_outputs = Vec::new();
    for (clip_idx, clip) in track.clips.iter().enumerate() {
      let clip_output = self
        .process_clip(clip, track_idx, clip_idx, context)
        .await?;
      clip_outputs.push(clip_output);
    }

    // –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–ª–∏–ø—ã –≤ –æ–¥–∏–Ω —Ç—Ä–µ–∫
    self
      .concatenate_clips(&clip_outputs, &track_output, context)
      .await?;

    log::debug!("‚úÖ –¢—Ä–µ–∫ {track_idx} –æ–±—Ä–∞–±–æ—Ç–∞–Ω");
    Ok(track_output)
  }

  /// –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–ª–∏–ø–∞
  async fn process_clip(
    &self,
    clip: &Clip,
    track_idx: usize,
    clip_idx: usize,
    context: &mut PipelineContext,
  ) -> Result<PathBuf> {
    log::debug!("üéûÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∏–ø–∞ {track_idx}:{clip_idx}");

    // –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
    let source_key = if matches!(
      clip.source,
      crate::video_compiler::schema::ClipSource::Generated
    ) {
      format!("generated_track_{track_idx}_clip_{clip_idx}")
    } else {
      format!("preprocessed_track_{track_idx}_clip_{clip_idx}")
    };

    let source_path = context.get_intermediate_file(&source_key).ok_or_else(|| {
      VideoCompilerError::InternalError(format!(
        "–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –∫–ª–∏–ø–∞ {track_idx}:{clip_idx} –Ω–µ –Ω–∞–π–¥–µ–Ω"
      ))
    })?;

    let clip_output = context.get_temp_file_path(&format!("clip_{track_idx}_{clip_idx}.mp4"));

    // –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–µ–∑–∫—É –≤—Ä–µ–º–µ–Ω–∏
    let trimmed_path = self
      .apply_time_trim(
        source_path,
        clip.start_time,
        clip.end_time,
        &context.get_temp_file_path(&format!("trimmed_{track_idx}_{clip_idx}.mp4")),
        context,
      )
      .await?;

    // –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã
    let effects_applied_path = if !clip.effects.is_empty() {
      // –ò—â–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –ø–æ ID
      let actual_effects: Vec<&Effect> = clip
        .effects
        .iter()
        .filter_map(|effect_id| context.project.effects.iter().find(|e| &e.id == effect_id))
        .collect();

      if !actual_effects.is_empty() {
        self
          .apply_effects(
            &trimmed_path,
            &actual_effects,
            &context.get_temp_file_path(&format!("effects_{track_idx}_{clip_idx}.mp4")),
            context,
          )
          .await?
      } else {
        trimmed_path
      }
    } else {
      trimmed_path
    };

    // –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    let filters_applied_path = if !clip.filters.is_empty() {
      // –ò—â–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ ID
      let actual_filters: Vec<&Filter> = clip
        .filters
        .iter()
        .filter_map(|filter_id| context.project.filters.iter().find(|f| &f.id == filter_id))
        .collect();

      if !actual_filters.is_empty() {
        self
          .apply_filters(
            &effects_applied_path,
            &actual_filters,
            &context.get_temp_file_path(&format!("filters_{track_idx}_{clip_idx}.mp4")),
            context,
          )
          .await?
      } else {
        effects_applied_path
      }
    } else {
      effects_applied_path
    };

    // –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
    self
      .apply_positioning(&filters_applied_path, clip, &clip_output, context)
      .await?;

    log::debug!("‚úÖ –ö–ª–∏–ø {track_idx}:{clip_idx} –æ–±—Ä–∞–±–æ—Ç–∞–Ω");
    Ok(clip_output)
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
  async fn apply_time_trim(
    &self,
    input_path: &PathBuf,
    start_time: f64,
    end_time: f64,
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<PathBuf> {
    let duration = end_time - start_time;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-ss")
      .arg(start_time.to_string())
      .arg("-t")
      .arg(duration.to_string())
      .arg("-c")
      .arg("copy")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(output_path.clone())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
  async fn apply_effects(
    &self,
    input_path: &Path,
    effects: &[&Effect],
    output_path: &Path,
    _context: &PipelineContext,
  ) -> Result<PathBuf> {
    let mut current_input = input_path.to_path_buf();

    for (temp_counter, effect) in effects.iter().enumerate() {
      let temp_output = if temp_counter == effects.len() - 1 {
        output_path.to_path_buf()
      } else {
        PathBuf::from(format!(
          "{}_temp_{}.mp4",
          output_path.file_stem().unwrap().to_string_lossy(),
          temp_counter
        ))
      };

      self
        .apply_single_effect(&current_input, effect, &temp_output)
        .await?;
      current_input = temp_output;
    }

    Ok(output_path.to_path_buf())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
  async fn apply_single_effect(
    &self,
    input_path: &PathBuf,
    effect: &Effect,
    output_path: &PathBuf,
  ) -> Result<()> {
    let filter_string = match effect.effect_type {
      crate::video_compiler::schema::effects::EffectType::AudioFadeIn => {
        let duration = effect
          .parameters
          .get("duration")
          .and_then(|d| match d {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(1.0);
        format!("fade=in:0:{duration}")
      }
      crate::video_compiler::schema::effects::EffectType::AudioFadeOut => {
        let duration = effect
          .parameters
          .get("duration")
          .and_then(|d| match d {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(1.0);
        format!("fade=out:st={duration}:d={duration}")
      }
      crate::video_compiler::schema::effects::EffectType::Blur => {
        let radius = effect
          .parameters
          .get("radius")
          .and_then(|r| match r {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(5.0);
        format!("boxblur={radius}")
      }
      crate::video_compiler::schema::effects::EffectType::Brightness => {
        let value = effect
          .parameters
          .get("value")
          .and_then(|v| match v {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(0.0);
        format!("eq=brightness={value}")
      }
      crate::video_compiler::schema::effects::EffectType::Contrast => {
        let value = effect
          .parameters
          .get("value")
          .and_then(|v| match v {
            crate::video_compiler::schema::effects::EffectParameter::Float(f) => Some(*f as f64),
            _ => None,
          })
          .unwrap_or(1.0);
        format!("eq=contrast={value}")
      }
      _ => {
        log::warn!("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç: {:?}", effect.effect_type);
        return Ok(());
      }
    };

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vf")
      .arg(filter_string)
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
  async fn apply_filters(
    &self,
    input_path: &PathBuf,
    filters: &[&Filter],
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<PathBuf> {
    let mut filter_chains = Vec::new();

    for filter in filters {
      let filter_string = match filter.filter_type {
        crate::video_compiler::schema::effects::FilterType::Brightness => {
          let value = filter.parameters.get("value").unwrap_or(&0.0);
          format!("eq=brightness={value}")
        }
        crate::video_compiler::schema::effects::FilterType::Contrast => {
          let value = filter.parameters.get("value").unwrap_or(&1.0);
          format!("eq=contrast={value}")
        }
        crate::video_compiler::schema::effects::FilterType::Saturation => {
          let value = filter.parameters.get("value").unwrap_or(&1.0);
          format!("eq=saturation={value}")
        }
        crate::video_compiler::schema::effects::FilterType::Blur => {
          let radius = filter.parameters.get("radius").unwrap_or(&5.0);
          format!("boxblur={radius}")
        }
        crate::video_compiler::schema::effects::FilterType::Sharpen => {
          "unsharp=5:5:1.0:5:5:0.0".to_string()
        }
        _ => {
          log::warn!("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–∏–ª—å—Ç—Ä: {:?}", filter.filter_type);
          continue;
        }
      };
      filter_chains.push(filter_string);
    }

    if filter_chains.is_empty() {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
      tokio::fs::copy(input_path, output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      return Ok(output_path.clone());
    }

    let combined_filter = filter_chains.join(",");

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vf")
      .arg(combined_filter)
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(output_path.clone())
  }

  /// –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
  async fn apply_positioning(
    &self,
    input_path: &PathBuf,
    clip: &Clip,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;

    // –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –∏ —Ä–∞–∑–º–µ—Ä –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    let default_transform = Default::default();
    let transform = clip.transform.as_ref().unwrap_or(&default_transform);
    let width = export_settings.resolution.width;
    let height = export_settings.resolution.height;
    let x = (transform.position_x * width as f32) as i32;
    let y = (transform.position_y * height as f32) as i32;
    let scaled_width = (transform.scale_x * width as f32) as i32;
    let scaled_height = (transform.scale_y * height as f32) as i32;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-i")
      .arg(input_path)
      .arg("-vf")
      .arg(format!(
        "scale={scaled_width}:{scaled_height},pad={width}:{height}:{x}:{y}:black"
      ))
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–ª–∏–ø–æ–≤ –≤ —Ç—Ä–µ–∫–µ
  async fn concatenate_clips(
    &self,
    clip_paths: &[PathBuf],
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<()> {
    if clip_paths.is_empty() {
      return Err(VideoCompilerError::InternalError(
        "–ù–µ—Ç –∫–ª–∏–ø–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è".to_string(),
      ));
    }

    if clip_paths.len() == 1 {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–ª–∏–ø
      tokio::fs::copy(&clip_paths[0], output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      return Ok(());
    }

    // –°–æ–∑–¥–∞–µ–º concat —Ñ–∞–π–ª
    let concat_file = output_path.parent().unwrap().join("concat_list.txt");
    let mut concat_content = String::new();

    for path in clip_paths {
      concat_content.push_str(&format!("file '{}'\n", path.display()));
    }

    tokio::fs::write(&concat_file, concat_content)
      .await
      .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("concat")
      .arg("-safe")
      .arg("0")
      .arg("-i")
      .arg(&concat_file)
      .arg("-c")
      .arg("copy")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π concat —Ñ–∞–π–ª
    let _ = tokio::fs::remove_file(&concat_file).await;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–ª–æ–µ–≤ (—Ç—Ä–µ–∫–æ–≤)
  async fn combine_layers(
    &self,
    layer_paths: &[PathBuf],
    output_path: &PathBuf,
    _context: &PipelineContext,
  ) -> Result<()> {
    if layer_paths.is_empty() {
      return Err(VideoCompilerError::InternalError(
        "–ù–µ—Ç —Å–ª–æ–µ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è".to_string(),
      ));
    }

    if layer_paths.len() == 1 {
      // –ü—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ª–æ–π
      tokio::fs::copy(&layer_paths[0], output_path)
        .await
        .map_err(|e| VideoCompilerError::IoError(e.to_string()))?;
      return Ok(());
    }

    // –°–æ–∑–¥–∞–µ–º —Å–ª–æ–∂–Ω—É—é —Ñ–∏–ª—å—Ç—Ä-—Å—Ö–µ–º—É –¥–ª—è overlay
    let mut command = tokio::process::Command::new("ffmpeg");

    // –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
    for path in layer_paths {
      command.arg("-i").arg(path);
    }

    // –°–æ–∑–¥–∞–µ–º filter_complex –¥–ª—è overlay
    let mut filter_complex = String::new();
    let mut current_label = "[0:v]".to_string();

    for i in 1..layer_paths.len() {
      let next_label = if i == layer_paths.len() - 1 {
        "[out]".to_string()
      } else {
        format!("[tmp{i}]")
      };

      filter_complex.push_str(&format!("{current_label}[{i}:v]overlay=0:0{next_label}; "));

      current_label = next_label.clone();
    }

    // –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π "; "
    filter_complex = filter_complex.trim_end_matches("; ").to_string();

    command
      .arg("-filter_complex")
      .arg(filter_complex)
      .arg("-map")
      .arg("[out]")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }

  /// –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ç—Ä–µ–∫–∞
  async fn create_empty_track(
    &self,
    output_path: &PathBuf,
    context: &PipelineContext,
  ) -> Result<()> {
    let export_settings = &context.project.settings;

    let mut command = tokio::process::Command::new("ffmpeg");
    command
      .arg("-f")
      .arg("lavfi")
      .arg("-i")
      .arg(format!(
        "color=black:size={}x{}:duration=1:rate={}",
        export_settings.resolution.width,
        export_settings.resolution.height,
        export_settings.frame_rate
      ))
      .arg("-c:v")
      .arg("libx264")
      .arg("-y")
      .arg(output_path);

    let output = command
      .output()
      .await
      .map_err(|e| VideoCompilerError::FFmpegError {
        exit_code: None,
        stderr: e.to_string(),
        command: "ffmpeg".to_string(),
      })?;

    if !output.status.success() {
      let error_msg = String::from_utf8_lossy(&output.stderr);
      return Err(VideoCompilerError::FFmpegError {
        exit_code: output.status.code(),
        stderr: error_msg.to_string(),
        command: "ffmpeg".to_string(),
      });
    }

    Ok(())
  }
}

#[async_trait]
impl PipelineStage for CompositionStage {
  async fn process(&self, context: &mut PipelineContext) -> Result<()> {
    log::info!("üé¨ === –≠—Ç–∞–ø –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ ===");

    // –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    context.update_progress(0, "Composition").await?;

    // –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–∑–∏—Ü–∏—é
    self.create_composition(context).await?;

    log::info!("‚úÖ –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ");
    Ok(())
  }

  fn name(&self) -> &str {
    "Composition"
  }

  fn estimated_duration(&self) -> Duration {
    Duration::from_secs(120) // –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
  }
}

impl Default for CompositionStage {
  fn default() -> Self {
    Self::new()
  }
}
